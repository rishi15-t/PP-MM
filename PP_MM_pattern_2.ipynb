{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PP-MM_pattern_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishi15-t/PP-MM/blob/master/PP_MM_pattern_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZyaSvq7Poeg",
        "colab_type": "code",
        "outputId": "3fd59368-ffc4-4feb-be70-810fa75f3fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daviCRfrPsDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_pickle('/content/drive/My Drive/dataset/w2v_vgg_embeddings.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lq5KYZXPtiv",
        "colab_type": "code",
        "outputId": "b6ff30be-5f58-403c-ebf4-20a89c48b54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def Train_Test_Val_Split(data , test_data_fraction = 0.3, val_data_fraction = 0.1) :\n",
        "    \n",
        "  \n",
        "    data_genres_one_hot_encoding = pd.DataFrame.from_items(zip(data['genres'].index, data['genres'].values)).T\n",
        "    Label_names = np.array(['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
        "       'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir',\n",
        "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'Romance',\n",
        "       'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western'])\n",
        "    data_genres_one_hot_encoding.columns = Label_names\n",
        "    Data_train, Data_test, Labels_train, Labels_test = train_test_split(data, data_genres_one_hot_encoding, test_size = test_data_fraction)\n",
        "\n",
        "    Data_train, Data_val, Labels_train, Labels_val = train_test_split(Data_train, Labels_train, test_size = val_data_fraction)\n",
        "\n",
        "    Data_train = Data_train.reset_index(drop=True)\n",
        "    Data_test = Data_test.reset_index(drop=True)\n",
        "    Data_val = Data_val.reset_index(drop=True)\n",
        "    \n",
        "    Labels_train = torch.tensor(Labels_train.values)\n",
        "    Labels_test = torch.tensor(Labels_test.values)\n",
        "    Labels_val = torch.tensor(Labels_val.values)\n",
        "    \n",
        "    return (Data_train, Data_test, Data_val, Labels_train, Labels_test, Labels_val, Label_names)\n",
        "    \n",
        "Data_train, Data_test, Data_val, Labels_train_tensor, Labels_test_tensor, Labels_val_tensor, Label_names = Train_Test_Val_Split(dataset)\n",
        "\n",
        "Data_train_tensor_text = torch.tensor(Data_train['w2v_embeddings'])\n",
        "Data_test_tensor_text = torch.tensor(Data_test['w2v_embeddings'])\n",
        "Data_val_tensor_text = torch.tensor(Data_val['w2v_embeddings'])\n",
        "\n",
        "Data_train_tensor_image = torch.tensor(Data_train['vgg16_embeddings'])\n",
        "Data_test_tensor_image = torch.tensor(Data_test['vgg16_embeddings'])\n",
        "Data_val_tensor_image = torch.tensor(Data_val['vgg16_embeddings'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9oDVZe52y9s",
        "colab_type": "code",
        "outputId": "8357fa9a-fd9f-4d55-a4b0-64fcc4f6eea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "!pip install git+https://github.com/uber/pyro.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/uber/pyro.git\n",
            "  Cloning https://github.com/uber/pyro.git to /tmp/pip-req-build-h2ssot4p\n",
            "  Running command git clone -q https://github.com/uber/pyro.git /tmp/pip-req-build-h2ssot4p\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==1.2.1+13b08a7c) (1.17.5)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==1.2.1+13b08a7c) (3.1.0)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/bc/6cdbd1929e32fff62a33592633c2cc0393c7f7739131ccc9c9c4e28ac8dd/pyro_api-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==1.2.1+13b08a7c) (1.4.0)\n",
            "Collecting tqdm>=4.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyro-ppl\n",
            "  Building wheel for pyro-ppl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyro-ppl: filename=pyro_ppl-1.2.1+13b08a7c-cp36-none-any.whl size=484817 sha256=6d37f86557422c7a06d69bb7f4f00354610f8f6f1ed79a678b961a7d3659d13e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-geuixd3r/wheels/3c/10/ed/73d2332a097e2e9dc7d601ca2a99b0b4f9634e393474b78137\n",
            "Successfully built pyro-ppl\n",
            "Installing collected packages: pyro-api, tqdm, pyro-ppl\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed pyro-api-0.1.1 pyro-ppl-1.2.1+13b08a7c tqdm-4.43.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgHNfFPtlceS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset, Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from torch import autograd, nn, tanh, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import softplus\n",
        "import numpy as np \n",
        "from pathlib import Path\n",
        "import pyro\n",
        "from pyro import poutine\n",
        "from pyro.distributions import Normal, Categorical, Laplace\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam, ClippedAdam\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "# models\n",
        "\n",
        "class Classify(nn.Module):\n",
        "    # Classifier\n",
        "    def __init__(self, out_dim1, out_dim2):\n",
        "        super(Classify, self).__init__()\n",
        "        self.out_dim1 = out_dim1\n",
        "        self.out_dim2 = out_dim2\n",
        "        self.c0 = nn.Linear(out_dim1, out_dim1)\n",
        "        self.c1 = nn.Linear(out_dim1, out_dim2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.out_dim1)\n",
        "        x = self.c0(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.c1(x)\n",
        "        x = torch.tanh(x)\n",
        "        return(x)\n",
        "        \n",
        "class GMU(nn.Module):\n",
        "    \n",
        "    def __init__(self, out_dim, textual_dim = 300, visual_dim = 4096, num_classes = 23, aux_loss_multiplier=None):\n",
        "        super(GMU, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.out_dim = out_dim\n",
        "\n",
        "        self.fc0 = nn.Linear(textual_dim, self.out_dim)\n",
        "        self.fc1 = nn.Linear(visual_dim, self.out_dim)\n",
        "        self.fc2 = nn.Linear(textual_dim + visual_dim, self.out_dim)\n",
        "        self.fc3 = nn.Linear(self.out_dim, self.num_classes)\n",
        "        self.class0 = Classify(self.out_dim, self.out_dim)\n",
        "\n",
        "    def forward(self, x_text, x_visual):\n",
        "\n",
        "        t = self.fc0(x_text)\n",
        "        t = torch.tanh(t)\n",
        "        v = self.fc1(x_visual)\n",
        "        v = torch.tanh(v)\n",
        "\n",
        "        concat = torch.cat((x_text, x_visual), 1)\n",
        "        attend = self.fc2(concat)\n",
        "        attend = torch.sigmoid(attend)\n",
        "        attend = attend * v + (1 - attend) * t\n",
        "        classify_out = self.class0(attend)\n",
        "        out = self.fc3(classify_out)\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwoH8yxZHHRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pyro functions\n",
        "\n",
        "\n",
        "def model(x_text, x_visual, x_label):\n",
        "\n",
        "        fc0_prior_w = Laplace(loc=torch.ones_like(net.fc0.weight), scale=torch.ones_like(net.fc0.weight))\n",
        "        fc0_prior_b = Laplace(loc=torch.ones_like(net.fc0.bias), scale=torch.ones_like(net.fc0.bias))\n",
        "        fc1_prior_w = Laplace(loc=torch.ones_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
        "        fc1_prior_b = Laplace(loc=torch.ones_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
        "        fc2_prior_w = Laplace(loc=torch.ones_like(net.fc2.weight), scale=torch.ones_like(net.fc2.weight))\n",
        "        fc2_prior_b = Laplace(loc=torch.ones_like(net.fc2.bias), scale=torch.ones_like(net.fc2.bias))\n",
        "        fc3_prior_w = Laplace(loc=torch.ones_like(net.fc3.weight), scale=torch.ones_like(net.fc3.weight))\n",
        "        fc3_prior_b = Laplace(loc=torch.ones_like(net.fc3.bias), scale=torch.ones_like(net.fc3.bias))\n",
        "\n",
        "        priors = {\n",
        "            'fc0.weight': fc0_prior_w, 'fc0.bias': fc0_prior_b,\n",
        "            'fc1.weight': fc1_prior_w, 'fc1.bias': fc1_prior_b,\n",
        "            'fc2.weight': fc2_prior_w, 'fc2.bias': fc2_prior_b,\n",
        "            'fc3.weight': fc3_prior_w, 'fc3.bias': fc3_prior_b}\n",
        "\n",
        "        lifted_module = pyro.random_module(\"gmu\", net, priors)\n",
        "        lifted_reg_model = lifted_module()\n",
        "        \n",
        "        with pyro.plate(\"map\"):\n",
        "            x_text = x_text\n",
        "            x_visual = x_visual\n",
        "            x_label = x_label\n",
        "        lhat = torch.sigmoid(lifted_reg_model(x_text, x_visual))\n",
        "        pyro.sample(\"obs\", Categorical(logits=lhat), obs=x_label)\n",
        "\n",
        "\n",
        "# pyro guide\n",
        "def guide(x_text, x_visual, x_label):\n",
        "\n",
        "        # First\n",
        "        # weight\n",
        "        fc0_loc_w = torch.randn_like(net.fc0.weight)\n",
        "        fc0_loc_param_w = softplus(pyro.param(\"fc0_loc_w\", fc0_loc_w)) # fix to 0.01\n",
        "        fc0_prior_w = Laplace(loc=fc0_loc_param_w, scale=fc0_loc_param_w)\n",
        "        # bias\n",
        "        fc0_loc_b = torch.randn_like(net.fc0.bias)\n",
        "        fc0_loc_param_b = softplus(pyro.param(\"fc0_loc_b\", fc0_loc_b)) # fix to 0.01\n",
        "        fc0_prior_b = Laplace(loc=fc0_loc_param_b, scale=fc0_loc_param_b)\n",
        "\n",
        "        # Second\n",
        "        # weight\n",
        "        fc1_loc_w = torch.randn_like(net.fc1.weight)\n",
        "        fc1_loc_param_w = softplus(pyro.param(\"fc1_loc_w\", fc1_loc_w))\n",
        "        fc1_prior_w = Laplace(loc=fc1_loc_param_w, scale=fc1_loc_param_w)\n",
        "        # bias\n",
        "        fc1_loc_b = torch.randn_like(net.fc1.bias)\n",
        "        fc1_loc_param_b = softplus(pyro.param(\"fc1_loc_b\", fc1_loc_b))\n",
        "        fc1_prior_b = Laplace(loc=fc1_loc_param_b, scale=fc1_loc_param_b)\n",
        "\n",
        "        # Third\n",
        "        # weight\n",
        "        fc2_loc_w = torch.randn_like(net.fc2.weight)\n",
        "        fc2_loc_param_w = softplus(pyro.param(\"fc2_loc_w\", fc2_loc_w))\n",
        "        fc2_prior_w = Laplace(loc=fc2_loc_param_w, scale=fc2_loc_param_w)\n",
        "        # bias\n",
        "        fc2_loc_b = torch.randn_like(net.fc2.bias)\n",
        "        fc2_loc_param_b = softplus(pyro.param(\"fc2_loc_b\", fc2_loc_b))\n",
        "        fc2_prior_b = Laplace(loc=fc2_loc_param_b, scale=fc2_loc_param_b)\n",
        "\n",
        "        # Fourth\n",
        "        # weight\n",
        "        fc3_loc_w = torch.randn_like(net.fc3.weight)\n",
        "        fc3_loc_param_w = softplus(pyro.param(\"fc3_loc_w\", fc3_loc_w))\n",
        "        fc3_prior_w = Laplace(loc=fc3_loc_param_w, scale=fc3_loc_param_w)\n",
        "        # bias\n",
        "        fc3_loc_b = torch.randn_like(net.fc3.bias)\n",
        "        fc3_loc_param_b = softplus(pyro.param(\"fc3_loc_b\", fc3_loc_b))\n",
        "        fc3_prior_b = Laplace(loc=fc3_loc_param_b, scale=fc3_loc_param_b)\n",
        "\n",
        "        priors = {\n",
        "        'fc0.weight': fc0_prior_w, 'fc0.bias': fc0_prior_b,\n",
        "        'fc1.weight': fc1_prior_w, 'fc1.bias': fc1_prior_b,\n",
        "        'fc2.weight': fc2_prior_w, 'fc2.bias': fc2_prior_b,\n",
        "        'fc3.weight': fc3_prior_w, 'fc3.bias': fc3_prior_b}\n",
        "\n",
        "        lifted_module = pyro.random_module(\"gmu\", net, priors)\n",
        "\n",
        "        with pyro.plate(\"map\"):\n",
        "            x_text = x_text\n",
        "            x_visual = x_visual\n",
        "            x_label = x_label\n",
        "        return lifted_module()\n",
        "\n",
        "\n",
        "# pyro model for auxiliary loss\n",
        "def model_classify(x_text, x_visual, x_label):\n",
        "        \"\"\"\n",
        "        this model is used to add an auxiliary (supervised) loss as described in the\n",
        "        Kingma et al., \"Semi-Supervised Learning with Deep Generative Models\".\n",
        "        \"\"\"\n",
        "        # register all pytorch (sub)modules with pyro\n",
        "        pyro.module(\"gmu\", net)\n",
        "\n",
        "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
        "        with pyro.plate(\"map\"):\n",
        "            x_label = x_label\n",
        "            # this here is the extra term to yield an auxiliary loss that we do gradient descent on\n",
        "            alpha = net.class0.forward(x)\n",
        "            with pyro.poutine.scale(scale=self.aux_loss_multiplier):\n",
        "                pyro.sample(\"label_aux\", dist.OneHotCategorical(alpha), obs=x_label)\n",
        "    \n",
        "def guide_classify(x_text, x_visual, x_label):\n",
        "        \"\"\"\n",
        "        dummy guide function to accompany model_classify in inference\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXrSeLOoxkZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training\n",
        "\n",
        "def SetTrainDataloader_MM(Data_train_tensor_text, Data_train_tensor_image, Labels_train_tensor) :\n",
        "\n",
        "  train_dataset = TensorDataset(Data_train_tensor_text, Data_train_tensor_image, Labels_train_tensor)\n",
        "  train_sampler = RandomSampler(train_dataset)\n",
        "  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size =  batch_size)\n",
        "  return(train_dataloader)\n",
        "\n",
        "\n",
        "#source: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "def Plot_Training_Epoch_Loss(epoch_loss_set) :\n",
        "\n",
        "  sns.set(style='darkgrid')\n",
        "  sns.set(font_scale=1.5)\n",
        "  plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "  plt.plot( epoch_loss_set, 'b-o')\n",
        "  plt.title(\"Training loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.savefig('Training_Epoch_Loss.png',bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#source: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "def format_time(elapsed):\n",
        "  '''\n",
        "  Takes a time in seconds and returns a string hh:mm:ss\n",
        "  '''\n",
        "  # Round to the nearest second.\n",
        "  elapsed_rounded = int(round((elapsed)))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "def Train() :\n",
        "  \n",
        "  net.cuda()\n",
        "  t0 = time.time() # Measure how long the entire training process takes\n",
        "\n",
        "  for _ in trange( epochs, desc=\"Epoch\"):\n",
        "    \n",
        "    net.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_aux_loss = 0\n",
        "    t1 = time.time() # Measure how long the training epoch takes\n",
        "\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "\n",
        "      # Progress update every 30 batches.\n",
        "      if step_num % 30 == 0 and not step_num == 0:\n",
        "        elapsed =  format_time(time.time() - t1)\n",
        "        print('  Batch : ',step_num, ' , Time elapsed : ',elapsed)\n",
        "\n",
        "      samples_text, samples_image, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "      batch_loss = inference.step(samples_text.float(), samples_image.float(), labels.t())\n",
        "      epoch_loss += batch_loss\n",
        "\n",
        "      #batch_aux_loss = loss_aux.step(samples_text.float(), samples_image.float(), labels.t())\n",
        "      #epoch_aux_loss += batch_aux_loss\n",
        "\n",
        "    avg_epoch_loss = epoch_loss/len( train_dataloader)\n",
        "    print(\"\\nTrain loss for epoch: \",avg_epoch_loss)\n",
        "    print(\"\\nTraining epoch took: {:}\".format( format_time(time.time() - t1)))\n",
        "    epoch_loss_set.append(avg_epoch_loss)\n",
        "\n",
        "    #avg_epoch_aux_loss = epoch_aux_loss/len( train_dataloader)\n",
        "    #epoch_aux_loss_set.append(avg_epoch_aux_los)\n",
        "\n",
        "  print(\"\\nTraining process took: {:}\".format( format_time(time.time() - t0)))\n",
        "  Plot_Training_Epoch_Loss(epoch_loss_set)\n",
        "  #Plot_Training_Epoch_Loss(epoch_aux_loss_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj8rNWGO_-hW",
        "colab_type": "code",
        "outputId": "40426cdd-27d8-41ae-bced-9251c0405f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Setting hyperparameters\n",
        "\n",
        "net = GMU(out_dim = 512).cuda()\n",
        "label_names = Label_names\n",
        "num_labels = 23\n",
        "batch_size = 512\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "results = pd.DataFrame(0, index=['Recall','Precision','F_Score'], columns=['micro', 'macro', 'weighted', 'samples']).astype(float)\n",
        "epoch_loss_set = []\n",
        "epoch_aux_loss_set = []\n",
        "train_dataloader =  SetTrainDataloader_MM(Data_train_tensor_text, Data_train_tensor_image, Labels_train_tensor)\n",
        "\n",
        "# clear param store\n",
        "pyro.clear_param_store()\n",
        "\n",
        "\n",
        "# trainable parameters\n",
        "def count_parameters_trainable(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "train_param_cnt = count_parameters_trainable(net)\n",
        "print('trainable parameter count', train_param_cnt)\n",
        "\n",
        "# Pyro param dictionary\n",
        "param_dict = pyro.get_param_store().items()\n",
        "print('para_dict', param_dict)\n",
        "\n",
        "for i in param_dict:\n",
        "    print (\"items\", i, param_dict[i])\n",
        "\n",
        "\n",
        "# custom ELBO loss\n",
        "def simple_mc_elbo(model, guide, *args):\n",
        "    guide_trace = poutine.trace(guide).get_trace(*args)\n",
        "    model_trace = poutine.trace(poutine.replay(model, trace=guide_trace)).get_trace(*args)\n",
        "    elbo = model_trace.log_prob_sum() - guide_trace.log_prob_sum()\n",
        "    return -elbo\n",
        "\n",
        "# pyro svi, initialise losses\n",
        "inference = SVI(model, guide, ClippedAdam({\"lr\": learning_rate}), loss=simple_mc_elbo)\n",
        "\n",
        "\n",
        "# pyro auxiliary loss\n",
        "loss_aux = SVI(model_classify, guide_classify, ClippedAdam({\"lr\": learning_rate}), loss=Trace_ELBO())\n",
        "\n",
        "\n",
        "Train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainable parameter count 5040151\n",
            "para_dict <generator object ParamStoreDict.items at 0x7f80aaff0e60>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:371: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
            "Epoch:   2%|▏         | 1/50 [00:01<01:11,  1.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  1741386.171875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   4%|▍         | 2/50 [00:02<01:02,  1.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  1251004.671875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   6%|▌         | 3/50 [00:04<01:10,  1.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  875103.90625\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   8%|▊         | 4/50 [00:05<01:01,  1.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  600195.015625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 5/50 [00:06<00:55,  1.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  407109.578125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  12%|█▏        | 6/50 [00:07<00:51,  1.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  275882.796875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  14%|█▍        | 7/50 [00:08<00:48,  1.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  189665.328125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  16%|█▌        | 8/50 [00:09<00:45,  1.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  134538.640625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  18%|█▊        | 9/50 [00:11<00:55,  1.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  100073.421875\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 10/50 [00:12<00:49,  1.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  78885.15625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  22%|██▏       | 11/50 [00:13<00:46,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  65999.203125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  24%|██▍       | 12/50 [00:14<00:43,  1.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  58237.8125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  26%|██▌       | 13/50 [00:16<00:51,  1.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  53578.015625\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  28%|██▊       | 14/50 [00:17<00:46,  1.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  50771.640625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 15/50 [00:18<00:42,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  49173.953125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  32%|███▏      | 16/50 [00:19<00:39,  1.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  48149.625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  34%|███▍      | 17/50 [00:20<00:36,  1.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  47616.015625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  36%|███▌      | 18/50 [00:21<00:35,  1.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  47244.875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  38%|███▊      | 19/50 [00:22<00:33,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  47135.953125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 20/50 [00:23<00:32,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46975.34375\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  42%|████▏     | 21/50 [00:24<00:30,  1.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46876.75\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  44%|████▍     | 22/50 [00:25<00:28,  1.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46871.03125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  46%|████▌     | 23/50 [00:26<00:27,  1.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46857.8125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  48%|████▊     | 24/50 [00:27<00:26,  1.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46894.109375\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 25/50 [00:28<00:25,  1.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46803.53125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  52%|█████▏    | 26/50 [00:30<00:30,  1.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  46858.90625\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  54%|█████▍    | 27/50 [00:31<00:27,  1.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46865.21875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  56%|█████▌    | 28/50 [00:32<00:25,  1.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46873.046875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  58%|█████▊    | 29/50 [00:33<00:23,  1.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46882.015625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 30/50 [00:34<00:21,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46848.296875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  62%|██████▏   | 31/50 [00:35<00:19,  1.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46858.390625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  64%|██████▍   | 32/50 [00:37<00:24,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  46837.421875\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  66%|██████▌   | 33/50 [00:38<00:20,  1.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46875.28125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  68%|██████▊   | 34/50 [00:39<00:18,  1.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46936.4375\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 35/50 [00:40<00:16,  1.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46882.171875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  72%|███████▏  | 36/50 [00:42<00:19,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  46915.703125\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  74%|███████▍  | 37/50 [00:43<00:16,  1.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46922.59375\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  76%|███████▌  | 38/50 [00:44<00:14,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46903.28125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  78%|███████▊  | 39/50 [00:45<00:12,  1.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46952.46875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 40/50 [00:46<00:10,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46904.28125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  82%|████████▏ | 41/50 [00:47<00:09,  1.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46911.796875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  84%|████████▍ | 42/50 [00:48<00:08,  1.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46948.203125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  86%|████████▌ | 43/50 [00:49<00:07,  1.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46943.078125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  88%|████████▊ | 44/50 [00:50<00:06,  1.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46931.328125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 45/50 [00:51<00:05,  1.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46939.921875\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  92%|█████████▏| 46/50 [00:52<00:04,  1.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46928.703125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  94%|█████████▍| 47/50 [00:53<00:03,  1.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46888.15625\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  96%|█████████▌| 48/50 [00:54<00:02,  1.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46930.078125\n",
            "\n",
            "Training epoch took: 0:00:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  98%|█████████▊| 49/50 [00:56<00:01,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:02\n",
            "\n",
            "Train loss for epoch:  46940.984375\n",
            "\n",
            "Training epoch took: 0:00:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 50/50 [00:57<00:00,  1.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch :  30  , Time elapsed :  0:00:01\n",
            "\n",
            "Train loss for epoch:  46931.828125\n",
            "\n",
            "Training epoch took: 0:00:01\n",
            "\n",
            "Training process took: 0:00:58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAGaCAYAAACWpgUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf4fKv8LgmglIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}